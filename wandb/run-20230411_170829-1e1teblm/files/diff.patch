diff --git a/models/TransformerEncoder.py b/models/TransformerEncoder.py
index 31a14cd..d4f4a34 100644
--- a/models/TransformerEncoder.py
+++ b/models/TransformerEncoder.py
@@ -2,6 +2,7 @@ from models.vn_layers import *
 import torch
 import torch.nn as nn
 from math import *
+from models.kernelization import *
 
 
 class TransformerEncoder(nn.Module):
@@ -25,6 +26,16 @@ class TransformerEncoder(nn.Module):
         self.wk = VNLinear(self.num_features, self.channels_per_head * self.heads)
         self.wv = VNLinear(self.num_features, self.channels_per_head * self.heads)
 
+        self.kernel = args.kernel
+        self.antithetic = args.antithetic
+        self.num_random = args.num_random
+        self.kernel_channel = self.channels_per_head * 3
+        if self.kernel:
+            if self.antithetic:
+                w = gaussian_orthogonal_random_matrix(nb_rows=self.num_random // 2, nb_columns=self.kernel_channel)
+                self.w = torch.cat([w, -w], dim=0).cuda()
+            else:
+                self.w = gaussian_orthogonal_random_matrix(nb_rows=self.num_random, nb_columns=self.kernel_channel)
 
 
     def forward(self, q, k, v):
@@ -54,17 +65,33 @@ class TransformerEncoder(nn.Module):
 
         # separated attention
         # B, H, N, N
-        div = 1 / sqrt(q.shape[-1])
-        attn = torch.einsum('...nc, ...mc->...nm', q, k)
-        attn *= div
-        attn = attn.softmax(-1)
+        if self.kernel:
+            if self.training:
+                if self.antithetic:
+                    w = gaussian_orthogonal_random_matrix(nb_rows=self.num_random // 2, nb_columns=self.kernel_channel)
+                    w = torch.cat([w, -w], dim=0).cuda()
+                else:
+                    w = gaussian_orthogonal_random_matrix(nb_rows=self.num_random, nb_columns=self.kernel_channel)
+
+            else:
+                w = self.w
+
+            k = softmax_kernel(data=k, projection_matrix=w, is_query=False)
+            q = softmax_kernel(data=q, projection_matrix=w, is_query=True)
+            out = compute_attn(q, k, v).contiguous()
+
+        else:
+            div = 1 / sqrt(q.shape[-1])
+            attn = torch.einsum('...nc, ...mc->...nm', q, k)
+            attn *= div
+            attn = attn.softmax(-1)
+
+            # B, H, N, C//H, 3 --> B, C//H * H, 3, N
+            out = torch.einsum('...nm, ...mcp->...ncp', attn, v)  # B, H, N, C//H, 3
 
-        # B, H, N, C//H, 3 --> B, C//H * H, 3, N
-        out = torch.einsum('...nm, ...mcp->...ncp', attn, v)  # B, H, N, C//H, 3
         out = out.permute(0, -1, 2, 3, 1).contiguous()
         out = out.view(B, -1, N, self.channels_per_head*self.heads)  # B, 3, N, C//H * H
         out = out.permute(0, -1, 1, 2)
-        #out = out.transpose(1, 2).transpose(-1, 1)  # B, C//H * H, 3, N
         out = self.out_linear(out)
 
         # add and norm
diff --git a/train_cls.py b/train_cls.py
index 5f0778a..a3b059c 100644
--- a/train_cls.py
+++ b/train_cls.py
@@ -50,6 +50,13 @@ def parse_args():
     parser.add_argument('--num_class', type=int, default=40,
                         help='Point Number [default: 1024]')
 
+    parser.add_argument('--kernel', action='store_true', default=False,
+                        help='Whether to use performer')
+    parser.add_argument('--antithetic', action='store_true', default=False,
+                        help='Whether to use antithetic sampling')
+    parser.add_argument('--num_random', type=int, default=20,
+                        help='Number of random features')
+
 
     parser.add_argument('--data_name', type=str, default='ModelNet40',
                         help='Point Number [default: 1024]')
